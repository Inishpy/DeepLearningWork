{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zr_NW0Aoi99JQARS2skn5xXX9J1lEN4O",
      "authorship_tag": "ABX9TyNBoor+PmQAWZph5z5AEXI2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inishpy/DeepLearningWork/blob/main/FlaskAppRunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask_socketio\n",
        "!pip install llama-cpp-python\n",
        "!pip install piper-tts\n",
        "!pip install pyaudio\n",
        "\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install sounddevice\n",
        "!pip install pydub\n",
        "!pip install espeak_phonemizer\n",
        "!pip install ollama\n"
      ],
      "metadata": {
        "id": "geWeNhLSSMYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6407804-af48-4978-ec0a-4db41c34f8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flask_socketio\n",
            "  Downloading Flask_SocketIO-5.3.6-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask_socketio) (2.2.5)\n",
            "Collecting python-socketio>=5.0.2 (from flask_socketio)\n",
            "  Downloading python_socketio-5.11.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_socketio) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_socketio) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_socketio) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_socketio) (8.1.7)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=5.0.2->flask_socketio) (0.23.1)\n",
            "Collecting python-engineio>=4.8.0 (from python-socketio>=5.0.2->flask_socketio)\n",
            "  Downloading python_engineio-4.9.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.9->flask_socketio) (2.1.5)\n",
            "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.8.0->python-socketio>=5.0.2->flask_socketio)\n",
            "  Downloading simple_websocket-1.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->flask_socketio)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto->simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=5.0.2->flask_socketio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: h11, wsproto, simple-websocket, python-engineio, python-socketio, flask_socketio\n",
            "Successfully installed flask_socketio-5.3.6 h11-0.14.0 python-engineio-4.9.0 python-socketio-5.11.1 simple-websocket-1.0.0 wsproto-1.2.0\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.55.tar.gz (36.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.10.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.25.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.55-cp310-cp310-manylinux_2_35_x86_64.whl size=2783050 sha256=ca52cf563313f93df9ec8ed3af94a5e406f13f247770d968bc3f7679e5c758e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/c9/bb/019dbfeef119ab5c29f76574b76070afa7b7755ccfbb3ee226\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.55\n",
            "Collecting piper-tts\n",
            "  Downloading piper_tts-1.2.0-py3-none-any.whl (29 kB)\n",
            "Collecting piper-phonemize~=1.1.0 (from piper-tts)\n",
            "  Downloading piper_phonemize-1.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (25.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnxruntime<2,>=1.11.0 (from piper-tts)\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime<2,>=1.11.0->piper-tts)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.11.0->piper-tts) (23.5.26)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.11.0->piper-tts) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.11.0->piper-tts) (23.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.11.0->piper-tts) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.11.0->piper-tts) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2,>=1.11.0->piper-tts)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.11.0->piper-tts) (1.3.0)\n",
            "Installing collected packages: piper-phonemize, humanfriendly, coloredlogs, onnxruntime, piper-tts\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1 piper-phonemize-1.1.0 piper-tts-1.2.0\n",
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: Could not build wheels for pyaudio, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.4.6\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Collecting espeak_phonemizer\n",
            "  Downloading espeak_phonemizer-1.3.1.tar.gz (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: espeak_phonemizer\n",
            "  Building wheel for espeak_phonemizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for espeak_phonemizer: filename=espeak_phonemizer-1.3.1-py3-none-any.whl size=19790 sha256=a0e54cf7ded7cfa372a06da34f12cdec294c7ec66819670f38aa8999bd44b699\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/9b/1e/bfa805aedc60435e5acf88a3144d8d29360891b390ce1b9889\n",
            "Successfully built espeak_phonemizer\n",
            "Installing collected packages: espeak_phonemizer\n",
            "Successfully installed espeak_phonemizer-1.3.1\n",
            "Collecting ollama\n",
            "  Downloading ollama-0.1.7-py3-none-any.whl (9.4 kB)\n",
            "Collecting httpx<0.26.0,>=0.25.2 (from ollama)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->ollama) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->ollama) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<0.26.0,>=0.25.2->ollama)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->ollama) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->ollama) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.2->ollama) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.26.0,>=0.25.2->ollama) (1.2.0)\n",
            "Installing collected packages: httpcore, httpx, ollama\n",
            "Successfully installed httpcore-1.0.4 httpx-0.25.2 ollama-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import pipeline\n",
        "import time\n",
        "\n",
        "from llama_cpp import Llama\n",
        "from huggingface_hub import hf_hub_download\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import requests\n",
        "#import sounddevice as sd\n",
        "\n",
        "\n",
        "import wave\n",
        "#import pyaudio\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import threading\n",
        "import time\n",
        "import queue\n",
        "import sys\n",
        "import re\n",
        "\n",
        "from queue import Queue\n",
        "from flask_socketio import SocketIO, emit\n",
        "#from jetsonGPTmain import webserver\n",
        "\n",
        "#import ollama\n",
        "\n",
        "\n",
        "# %%\n",
        "#pip install torch\n",
        "#pip install transformers\n",
        "#!pip install sounddevice\n",
        "#!pip install pydub\n",
        "#!pip install espeak_phonemizer\n",
        "\n",
        "# %%\n",
        "def print_with_newline(string):\n",
        "    words = string.split()\n",
        "    for i in range(0, len(words), 10):\n",
        "        print(' '.join(words[i:i+10]))\n",
        "\n",
        "def replace_apostrophes(string):\n",
        "    return string.replace('\"', \"'\")\n",
        "\n",
        "# %%\n",
        "#!pip install llama-cpp-python\n",
        "#!pip install piper-tts\n",
        "#!pip install pyaudio\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "\n",
        "#pipe = pipeline(\"automatic-speech-recognition\", \"openai/whisper-tiny\")\n",
        "#pipe1 =  pipeline(\"automatic-speech-recognition\", \"openai/whisper-base\")\n",
        "#pipe2 = pipeline(\"automatic-speech-recognition\", \"openai/whisper-small\")\n",
        "#pipe3 = pipeline(\"automatic-speech-recognition\", \"openai/whisper-medium\")\n",
        "#pipe4 = pipeline(\"automatic-speech-recognition\", \"openai/whisper-large-v2\")\n",
        "# {'text': \"GOING ALONG SLUSHY COUNTRY ROADS AND SPEAKING TO DAMP AUDIENCES IN DRAUGHTY SCHOOL ROOMS DAY AFTER DAY FOR A FORTNIGHT HE'LL HAVE TO PUT IN AN APPEARANCE AT SOME PLACE OF WORSHIP ON SUNDAY MORNING AND HE CAN COME TO US IMMEDIATELY AFTERWARDS\"}\n",
        "\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def record_audio(file_path, duration=5, sample_rate=44100):\n",
        "    print(f\"Recording audio for {duration} seconds...\")\n",
        "\n",
        "    # Initialize PyAudio\n",
        "    audio = pyaudio.PyAudio()\n",
        "\n",
        "    # Define audio stream parameters\n",
        "    chunk_size = 1024  # Adjust the chunk size as needed\n",
        "    format = pyaudio.paInt16\n",
        "    channels = 2\n",
        "\n",
        "    # Open audio stream\n",
        "    stream = audio.open(format=format,\n",
        "                        channels=channels,\n",
        "                        rate=sample_rate,\n",
        "                        input=True,\n",
        "                        frames_per_buffer=chunk_size)\n",
        "\n",
        "    frames = []\n",
        "    # Record audio for the specified duration\n",
        "    for _ in range(0, int(sample_rate / chunk_size * duration)):\n",
        "        data = stream.read(chunk_size)\n",
        "\n",
        "\n",
        "        frames.append(data)\n",
        "\n",
        "\n",
        "    # Stop and close the audio stream\n",
        "    stream.stop_stream()\n",
        "    stream.close()\n",
        "    audio.terminate()\n",
        "\n",
        "    print(\"Recording complete. Saving to file.\")\n",
        "\n",
        "    array_data = np.frombuffer(b''.join(frames), dtype=np.float16)\n",
        "    #b  = pipe1({\"sampling_rate\":  44100, \"raw\": array_data})['text']\n",
        "    #print(b)\n",
        "\n",
        "    # Save audio data to a WAV file\n",
        "    with wave.open(file_path, 'wb') as wf:\n",
        "        wf.setnchannels(channels)\n",
        "        wf.setsampwidth(audio.get_sample_size(format))\n",
        "        wf.setframerate(sample_rate)\n",
        "        wf.writeframes(b''.join(frames))\n",
        "\n",
        "    print(f\"Audio saved to {file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# %%\n",
        "#!pip install torchaudio\n",
        "\n",
        "# %%\n",
        "\n",
        "\n",
        "# %%\n",
        "global_stop_event = threading.Event()\n",
        "\n",
        "def my_function(thread_lock, thread_id, sentence):\n",
        "    with thread_lock:\n",
        "\n",
        "        if not global_stop_event.is_set():\n",
        "\n",
        "            st = time.time()\n",
        "            # Read audio data from stdin\n",
        "            data = webserver.predict(sentence)\n",
        "            end = time.time()\n",
        "            #print(\"script\", end - st)\n",
        "            npa = np.asarray(data['data'], dtype=np.int16)\n",
        "            sd.play(npa, data['sample-rate'], blocking=True)\n",
        "\n",
        "\n",
        "def worker(thread_lock, thread_id, sentence_queue):\n",
        "    while True:\n",
        "        sentence = sentence_queue.get()\n",
        "        if sentence is None:\n",
        "            break\n",
        "        my_function(thread_lock, thread_id, sentence)\n",
        "        sentence_queue.task_done()\n",
        "\n",
        "\n",
        "#model = \"./phi-2-dpo.Q5_K_S.gguf\"\n",
        "model = hf_hub_download(repo_id=\"TheBloke/phi-2-dpo-GGUF\", filename=\"phi-2-dpo.Q5_K_S.gguf\")\n",
        "llm = Llama(model_path=model, chat_format=\"llama-2\" )  # Set chat_format according to the model you are using\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def modelRun(textinput=False, input=\"\"):\n",
        "\n",
        "\n",
        "    Ollama = False\n",
        "    #record_audio(\"recorded_audio.wav\", duration=6)\n",
        "    print(\"recorded\")\n",
        "\n",
        "    if textinput == True:\n",
        "        QUERY = input\n",
        "    else:\n",
        "        record_audio(\"recorded_audio.wav\", duration=6)\n",
        "        QUERY = pipe1(\"recorded_audio.wav\")['text']\n",
        "    print(QUERY)\n",
        "\n",
        "\n",
        "    # Chat Completion API\n",
        "    thread_lock = threading.Lock()\n",
        "    sentence_queue = queue.Queue()\n",
        "\n",
        "    #Create worker threads\n",
        "\n",
        "    workers = []\n",
        "\n",
        "    output = \"\"\" \"\"\"\n",
        "    cur_sentence = \"\"\n",
        "\n",
        "    if Ollama == True:\n",
        "        stream = ollama.chat(\n",
        "        model='phi',\n",
        "        messages=[{'role': 'user', 'content': QUERY}],\n",
        "        stream=True,\n",
        "    )\n",
        "\n",
        "        for chunk in stream:\n",
        "\n",
        "            if global_stop_event.is_set():\n",
        "                return\n",
        "\n",
        "            character = chunk['message']['content']\n",
        "            print(character)\n",
        "            #emit('sentence', {'message': character})\n",
        "            output += character\n",
        "            cur_sentence += character\n",
        "            #print(character)\n",
        "\n",
        "\n",
        "            if re.search(r'[.,]$', character):#detect fullstop at the end of the sentence\n",
        "                # Enqueue the sentence\n",
        "                sentence_queue.put(cur_sentence)\n",
        "\n",
        "\n",
        "                cur_sentence = \"\"\n",
        "                worker_thread = threading.Thread(target=worker, args=(thread_lock, 1, sentence_queue))\n",
        "                worker_thread.start()\n",
        "                workers.append(worker_thread)\n",
        "    else:\n",
        "\n",
        "        for token in  (llm.create_chat_completion(\n",
        "            messages = [\n",
        "                # {\"role\": \"system\", \"content\": \"You are a story writing assistant.\"},\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": QUERY + \".\"\n",
        "                }\n",
        "            ],\n",
        "            stream = True,\n",
        "            max_tokens = 200\n",
        "        )):\n",
        "            character = token['choices'][0]['delta'].get('content', \"\")\n",
        "            print(character)\n",
        "            emit('sentence', {'data': character})\n",
        "            output += character\n",
        "            \"\"\"\n",
        "            cur_sentence += character\n",
        "            #print(character)\n",
        "\n",
        "\n",
        "            if re.search(r'[.,]$', character):#detect fullstop at the end of the sentence\n",
        "                # Enqueue the sentence\n",
        "                sentence_queue.put(cur_sentence)\n",
        "\n",
        "                cur_sentence = \"\"\n",
        "                worker_thread = threading.Thread(target=worker, args=(thread_lock, 1, sentence_queue))\n",
        "                worker_thread.start()\n",
        "                workers.append(worker_thread)\n",
        "\n",
        "    if cur_sentence != \"\":\n",
        "        sentence_queue.put(cur_sentence)\n",
        "        cur_sentence = \"\"\n",
        "\n",
        "        worker_thread = threading.Thread(target=worker, args=(thread_lock, 1, sentence_queue))\n",
        "        worker_thread.start()\n",
        "        workers.append(worker_thread)\n",
        "\n",
        "\n",
        "    # Wait for all sentences to be processed\n",
        "    sentence_queue.join()\n",
        "\n",
        "    # Stop worker threads by adding None to the queue\n",
        "    for _ in range(len(workers)):\n",
        "        sentence_queue.put(None)\n",
        "\n",
        "    # Wait for worker threads to finish\n",
        "    for worker_thread in workers:\n",
        "        worker_thread.join()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"------------------------------------------\")\n",
        "    print_with_newline(output)\n",
        "    print(\"------------------------------------------\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vJj52hOrOPW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gevent-websocket"
      ],
      "metadata": {
        "id": "AyGEElqkVwLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['GEVENT_SUPPORT'] = 'True'"
      ],
      "metadata": {
        "id": "kHhN9es_Xh0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gevent import monkey\n",
        "monkey.patch_all()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn7rv4O0Wx3L",
        "outputId": "dc5e06f5-6aa1-499a-aef9-73fc95a940b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "<ipython-input-6-1bad42606e85>:2: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['aiohttp.client_exceptions (/usr/local/lib/python3.10/dist-packages/aiohttp/client_exceptions.py)', 'urllib3.util (/usr/local/lib/python3.10/dist-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/usr/local/lib/python3.10/dist-packages/urllib3/util/ssl_.py)', 'aiohttp.client_reqrep (/usr/local/lib/python3.10/dist-packages/aiohttp/client_reqrep.py)', 'aiohttp.connector (/usr/local/lib/python3.10/dist-packages/aiohttp/connector.py)']. \n",
            "  monkey.patch_all()\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "iKnsmDDzXuUj",
        "outputId": "fa1f81d0-be13-4579-b04a-6b8353ddd52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://w7b04mr1n8-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))\n",
        "\n",
        "\n",
        "from flask import Flask, render_template, request\n",
        "from flask_socketio import SocketIO, emit\n",
        "import time\n",
        "app = Flask(__name__, template_folder='/content/drive/MyDrive/Rogerflask/templates')\n",
        "#import roger\n",
        "# Replace with a strong secret key\n",
        "socketio = SocketIO(app, async_mode='gevent')\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "\n",
        "@socketio.on('connect')\n",
        "def handle_connect():\n",
        "    print('Client connected!')\n",
        "    emit('connected', {'message': 'Welcome!'})\n",
        "\n",
        "\n",
        "@socketio.on('start')\n",
        "def handle_message(data):\n",
        "    global_stop_event.clear()\n",
        "    query = data[\"input\"]\n",
        "    if query == \"\":\n",
        "        modelRun(False)\n",
        "    else:\n",
        "        modelRun(True, query)\n",
        "\n",
        "\n",
        "@socketio.on('stopmodel')\n",
        "def stop_model():\n",
        "    print(\"stop-model-receidved\")\n",
        "    global_stop_event.set()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  app.run()\n",
        "  #socketio.run(app, allow_unsafe_werkzeug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vCNQAAe0ThNX",
        "outputId": "6c884aa5-8af3-4c9d-f51c-c36b4d34f65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "KeyboardInterrupt\n",
            "2024-03-04T12:10:45Z\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4516c4ee3cf7>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;31m#app.run()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m   \u001b[0msocketio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_unsafe_werkzeug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flask_socketio/__init__.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, app, host, port, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m                 \u001b[0mrun_with_reloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_server\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mreloader_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwsgi_server\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gevent/baseserver.py\u001b[0m in \u001b[0;36mserve_forever\u001b[0;34m(self, stop_timeout)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mGreenlet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gevent/_gevent_cevent.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mgevent._gevent_cevent.Event.wait\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gevent/_gevent_c_abstract_linkable.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._wait\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gevent/_gevent_c_abstract_linkable.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._wait_core\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gevent/_gevent_c_abstract_linkable.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._wait_core\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gevent/_gevent_c_abstract_linkable.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._AbstractLinkable__wait_to_be_notified\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gevent/_gevent_c_abstract_linkable.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mgevent._gevent_c_abstract_linkable.AbstractLinkable._switch_to_hub\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gevent/_gevent_c_greenlet_primitives.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gevent/_gevent_c_greenlet_primitives.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mgevent._gevent_c_greenlet_primitives.SwitchOutGreenletWithLoop.switch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/gevent/_gevent_c_greenlet_primitives.pxd\u001b[0m in \u001b[0;36mgevent._gevent_c_greenlet_primitives._greenlet_switch\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n",
            "It seems that the gevent monkey-patching is being used.\n",
            "Please set an environment variable with:\n",
            "GEVENT_SUPPORT=True\n",
            "to enable gevent support in the debugger.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install https://github.com/eventlet/eventlet/archive/master.zip"
      ],
      "metadata": {
        "id": "10HKS2nYGI1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gunicorn --worker-class eventlet -w 1 module:app"
      ],
      "metadata": {
        "id": "YkqLbAHnZYx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gunicorn\n",
        "!pip install eventlet\n",
        "!pip install gevent"
      ],
      "metadata": {
        "id": "m-UUJLXBbSXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "USetMwpoJZNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gunicorn -k gevent -w 1 wsgi:app"
      ],
      "metadata": {
        "id": "QYlHb7U1bXio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b4NzyCqSI9rX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/eventlet/eventlet/archive/master.zip"
      ],
      "metadata": {
        "id": "CmCGgZpqb8ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70VvxRI0GE92"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "9SnMp30rGRIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port_no = 5000"
      ],
      "metadata": {
        "id": "mWJhwXIJFEAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "ngrok.set_auth_token(\"2dDg3t3XLJu0CE56k8QnqVsVh7p_67VUuJGu2eE19XGDLHKkJ\")\n",
        "public_url =  ngrok.connect(port_no).public_url\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return f\"Running Flask on Google Colab!\"\n",
        "\n",
        "print(f\"To acces the Gloable link please click {public_url}\")\n",
        "\n",
        "app.run(port=port_no)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWRxu-WoE-zy",
        "outputId": "baee1265-b165-47fb-80d3-b84fb4f33dd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To acces the Gloable link please click https://b6a4-35-190-172-102.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Mar/2024 11:46:23] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [04/Mar/2024 11:46:24] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "WARNING:pyngrok.process.ngrok:t=2024-03-04T11:50:50+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-4df8aeb1-2365-4a04-bf8e-79efbbe62d5d acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ]
    }
  ]
}