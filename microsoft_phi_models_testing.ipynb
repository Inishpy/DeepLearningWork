{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPqLfSfVSnwEw9qT3XDiu1e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inishpy/DeepLearningWork/blob/main/microsoft_phi_models_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCRlL9_J74Y6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "torch.set_default_device(\"cuda\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model1 = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", torch_dtype=\"auto\", trust_remote_code=True)\n",
        "tokenizer1 = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\n",
        "\n",
        "\n",
        "#model2 = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True)\n",
        "#tokenizer2 = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
        "\n",
        "#model2 = AutoModelForCausalLM.from_pretrained(\"TheBloke/phi-2-dpo-GGUF\", torch_dtype=\"auto\", trust_remote_code=True)\n",
        "#tokenizer2 = AutoTokenizer.from_pretrained(\"TheBloke/phi-2-dpo-GGUF\", trust_remote_code=True)"
      ],
      "metadata": {
        "id": "fZP-n-FI9FGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "query = \"how far is italy from moscow\"\n",
        "\n",
        "\n",
        "inputs1 = tokenizer1(query, return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "outputs1 = model1.generate(**inputs1, max_length=200)\n",
        "text1 = tokenizer1.batch_decode(outputs1)[0]\n",
        "print(\"MODEL1\" , text1)\n",
        "\n",
        "inputs2 = tokenizer2(query, return_tensors=\"pt\", return_attention_mask=False)\n",
        "\n",
        "outputs2 = model2.generate(**inputs2, max_length=200)\n",
        "text2 = tokenizer2.batch_decode(outputs2)[0]\n",
        "print(\"MODEL2\" , text2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkA-RDcBuDai",
        "outputId": "4e26fcfd-3356-4f8d-ddfd-16356e83580f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL1 how far is italy from moscow?\"\n",
            "\n",
            "\"It's about 2,000 kilometers away,\" replied John.\n",
            "\n",
            "\"Wow, that's a long way,\" said Sarah.\n",
            "\n",
            "\"Yeah, it is. But it's worth it to see the beautiful landscapes and experience the different cultures,\" said John.\n",
            "\n",
            "\"I agree. It's always good to step out of your comfort zone and explore new places,\" said Sarah.\n",
            "\n",
            "As they continued their conversation, they realized that they had learned a lot from each other. They had discussed the importance of being careful with their belongings, the benefits of reading books, and the distance between two cities. They had also shared their experiences and knowledge, which had enriched their lives. They felt grateful for their friendship and the opportunity to learn from each other.<|endoftext|>\n",
            "\n",
            "\n",
            "In the heart of the bustling city of Chicago, as the sun began to set, a group of individuals gathered in a cozy room. They were members of a\n",
            "MODEL2 how far is italy from moscow\n",
            "    \"\"\"\n",
            "    return math.sqrt((lat2 - lat1)**2 + (lon2 - lon1)**2)\n",
            "\n",
            "<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SJdBAGRV9bZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jzqrP--l9bbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JDZzBdj99bet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObYEXKrS4Mw6",
        "outputId": "24287b2b-8c6f-4653-b03d-e3efdc65a372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 179588, done.\u001b[K\n",
            "remote: Counting objects: 100% (540/540), done.\u001b[K\n",
            "remote: Compressing objects: 100% (254/254), done.\u001b[K\n",
            "remote: Total 179588 (delta 311), reused 406 (delta 224), pack-reused 179048\u001b[K\n",
            "Receiving objects: 100% (179588/179588), 199.57 MiB | 24.33 MiB/s, done.\n",
            "Resolving deltas: 100% (125649/125649), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekakMtn14OCr",
        "outputId": "bc3d3c50-9d41-475c-9cc3-a904a1dd5dfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "6jS4KEiM4bld",
        "outputId": "67d31cc3-efb8-4a8a-a125-a62ec43ca619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.0.dev0) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.0.dev0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.0.dev0) (2023.11.17)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building editable for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.38.0.dev0-0.editable-py3-none-any.whl size=41789 sha256=96013ac04524d9df6f36321c8c9141ff9e06c3a18ef959a33dd95b072963f254\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lfjxsska/wheels/7c/35/80/e946b22a081210c6642e607ed65b2a5b9a4d9259695ee2caf5\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "Successfully installed transformers-4.38.0.dev0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli model info TheBloke/phi-2-dpo-GGUF\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fykwaZBy4gHB",
        "outputId": "8389e0a5-7d9e-469c-c315-5d5dd22d9001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: huggingface-cli <command> [<args>]\n",
            "huggingface-cli: error: argument {env,login,whoami,logout,repo,upload,download,lfs-enable-largefiles,lfs-multipart-upload,scan-cache,delete-cache}: invalid choice: 'model' (choose from 'env', 'login', 'whoami', 'logout', 'repo', 'upload', 'download', 'lfs-enable-largefiles', 'lfs-multipart-upload', 'scan-cache', 'delete-cache')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"TheBloke/phi-2-dpo-GGUF\")"
      ],
      "metadata": {
        "id": "Vt9zRTLZ54hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "setTjdZnL4g5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}